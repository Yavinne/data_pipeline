# Pipeline ETL - Open Data QualitÃ© de lâ€™air

## Table des matiÃ¨res
1. [Contexte & Objectifs](#contexte--objectifs)  
2. [Stack Technique](#stack-technique)  
3. [Sources de DonnÃ©es](#sources-de-donnÃ©es)  
4. [Architecture du Pipeline](#architecture-du-pipeline)  
5. [Installation & Lancement](#installation--lancement)  
6. [ModÃ¨le de DonnÃ©es](#modÃ¨le-de-donnÃ©es)  
7. [RÃ©sultats Attendus](#rÃ©sultats)  
8. [AmÃ©liorations Possibles](#amÃ©liorations-possibles)  
9. [Licence](#licence)  
10. [Contacts](#contacts)  

---

## Contexte & Objectifs
Lâ€™entreprise fictive **GreenAir Analytics** aide les municipalitÃ©s Ã  analyser la qualitÃ© de lâ€™air dans les grandes villes franÃ§aises afin de :  
- DÃ©tecter les pics de pollution (PM10, NOâ‚‚, Oâ‚ƒ).  
- Produire des rapports journaliers pour les autoritÃ©s locales.  
- Mettre Ã  disposition une base de donnÃ©es fiable pour alimenter des dashboards BI.  

ğŸ‘‰ Ce projet consiste Ã  mettre en place un **pipeline ETL automatisÃ©** permettant dâ€™ingÃ©rer des donnÃ©es de qualitÃ© de lâ€™air depuis une API Open Data, de les nettoyer et de les stocker dans une base PostgreSQL pour exploitation analytique.  

[ğŸ” Back to top](#table-des-matiÃ¨res)  

---

## Stack Technique
- **Langage** : Python 3.13  
- **Orchestration** : Apache Airflow  
- **Stockage** : PostgreSQL (extensible Ã  MySQL ou BigQuery)  
- **Transformation** : Pandas / SQL  
- **Containerisation** : Docker & Docker Compose  
- **Tests** : Pytest  

[ğŸ” Back to top](#table-des-matiÃ¨res)  

---

## Sources de DonnÃ©es
- **Fournisseur** : [API Open Data - QualitÃ© de lâ€™air Paris](https://opendata.paris.fr/explore/dataset/)  
- **Format** : JSON / CSV  
- **Contenu** : mesures journaliÃ¨res des polluants (PM10, NOâ‚‚, Oâ‚ƒ) par ville/zone gÃ©ographique  
- **Volume estimÃ©** : quelques Mo par jour  

[ğŸ” Back to top](#table-des-matiÃ¨res)  

---

## Architecture du Pipeline
```mermaid
flowchart LR
    A[API Open Data] --> B[Airflow Extract Task]
    B --> C[Transform (Pandas)]
    C --> D[Load into PostgreSQL]
    D --> E[Analytical Queries / BI Tools]
```

[ğŸ” Back to top](#table-des-matiÃ¨res)

---

## Installation & Lancement

### Cloner le repo
git clone https://github.com/username/pipeline-etl-air-quality.git
cd pipeline-etl-air-quality

### Lancer les services
docker-compose up -d

### AccÃ©der aux outils

Airflow UI â†’ http://localhost:8080

PostgreSQL â†’ localhost:5432 (credentials dans .env)

### Lancer le DAG

Activer le DAG etl_air_quality dans Airflow et exÃ©cuter le pipeline.

[ğŸ” Back to top](#table-des-matiÃ¨res)

---

## ModÃ¨le de DonnÃ©es
```mermaid
CREATE TABLE air_quality (
    id SERIAL PRIMARY KEY,
    city VARCHAR(255),
    date DATE,
    pm10 FLOAT,
    no2 FLOAT,
    o3 FLOAT,
    created_at TIMESTAMP DEFAULT NOW()
);
```

[ğŸ” Back to top](#table-des-matiÃ¨res)

---

## RÃ©sultats
- DonnÃ©es brutes ingÃ©rÃ©es automatiquement chaque jour.
- DonnÃ©es nettoyÃ©es et standardisÃ©es (colonnes homogÃ¨nes).
- Base PostgreSQL exploitable directement pour requÃªtes SQL et BI.

Exemple dâ€™usage : un dashboard Power BI ou Metabase affichant lâ€™Ã©volution de la pollution par ville.

[ğŸ” Back to top](#table-des-matiÃ¨res)

---

## AmÃ©liorations Possibles

Ajouter des contrÃ´les qualitÃ© avec Great Expectations.

Mettre en place du monitoring avec Prometheus + Grafana.

DÃ©ployer sur un cloud (GCP/AWS/Azure).

CrÃ©er une API REST pour exposer les donnÃ©es nettoyÃ©es.

[ğŸ” Back to top](#table-des-matiÃ¨res)

---

## Licence

Ce projet est sous licence MIT.

---

## Contacts

ğŸ‘¤ Auteur : Vulfran NDONG
ğŸ“§ Email : vianneyasog@gmail.com

ğŸ’¼ LinkedIn : linkedin.com/in/tonprofil

ğŸ™ GitHub : github.com/Yavinne